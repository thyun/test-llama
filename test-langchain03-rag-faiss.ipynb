{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c858ef2-bcd6-4214-bcc5-9b1c7344003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db39a17-c664-499c-90d8-233b0fcb98b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (0.0.311)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/ff/f2/e43aee1d628f4b46f06dcfd5072b2acb14f9d9196c40997ced0fbad972de/langchain-0.0.345-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.345-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: openai in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/3e/d3/309769dad11d5f75b81c7252d9dc849ed440d0921215e759af169054f3b6/openai-1.3.7-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: chromadb in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (0.4.14)\n",
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/0d/e9/117169df4027a5475ec6406c49f4c5f0ed2b7a7e46d10f02ab5fc049e9ca/chromadb-0.4.18-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchainhub\n",
      "  Obtaining dependency information for langchainhub from https://files.pythonhosted.org/packages/9c/99/4306b825b9462c824fd6d8dcb959309fb5e654c0d7b6473c5379388a82e9/langchainhub-0.1.14-py3-none-any.whl.metadata\n",
      "  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\n",
      "Requirement already satisfied: bs4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Collecting langchain-core<0.1,>=0.0.9 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.1,>=0.0.9 from https://files.pythonhosted.org/packages/7c/4f/9ad1deef19e886500ba9a80e4025104d769fd14e5cab531f72c5bb06d10a/langchain_core-0.0.9-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.0.9-py3-none-any.whl.metadata (750 bytes)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.63 from https://files.pythonhosted.org/packages/ea/09/e1458ea0a26037740aac27319479aaa79053a06413b5d715d56d37371b55/langsmith-0.0.69-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.69-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sniffio in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.103.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (1.16.1)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/51/3a/945e6c21f405ac4ea526f91ee09cc1568c04e0c95d3392903e6984c8f0e0/opentelemetry_api-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.21.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/75/59/ec3e39fe164c61306998cdd3cd30a857c4da2f8d3141204a929e57668eee/opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/0a/47/411f4dd5560f004c4d59e977fb6e1f511babfc399f3656b6eafd8f67c0ce/opentelemetry_instrumentation_fastapi-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.42b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/c3/08/ca8b1ef7a2fa3f1ea2f12770eca8976098066adb442b1da81fea3b370123/opentelemetry_sdk-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_sdk-1.21.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.14.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (6.1.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (1.59.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/f5/6a/1f69c2d8b1ff03f8d8e10d801f4ac3016ed4c1b00aa9795732c6ec900bba/kubernetes-28.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading kubernetes-28.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Obtaining dependency information for mmh3>=4.0.1 from https://files.pythonhosted.org/packages/b7/e2/64671cd50123f646073b078de39751ff5ad9665e9a8ed247ab6b3cf8a8fd/mmh3-4.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading mmh3-4.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/1d/d6/1281c1d7b03a127562d6644ebff081e85045f0025b1fe26dcdd82811ad1a/types_requests-2.31.0.10-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.10-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: certifi in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for google-auth>=1.0.1 from https://files.pythonhosted.org/packages/ca/7e/2d41727aeba37b84e1ca515fbb2ca0d706c591ca946236466ffe575b2059/google_auth-2.24.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.24.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<2.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for urllib3<2.0,>=1.24.2 from https://files.pythonhosted.org/packages/b0/53/aa91e163dcfd1e5b82d8a890ecf13314e3e149c05270cc644581f77f17fd/urllib3-1.26.18-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: coloredlogs in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
      "Requirement already satisfied: protobuf in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.4)\n",
      "Requirement already satisfied: sympy in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/21/49/12996dc0238e017504dceea1d121a48bd49fb3f4416f40d59fc3e924b4f3/googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.21.0 from https://files.pythonhosted.org/packages/2a/60/ec618caf8fd8a4ac50500565eb49038ec42b7b168df9a316494085a740a6/opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.21.0 from https://files.pythonhosted.org/packages/69/c2/d11b5fbf95adf68440ff4c953e2d8d027c9c62ece79b78372af95af590c9/opentelemetry_proto-1.21.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.21.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.42b0 from https://files.pythonhosted.org/packages/a9/ef/ac6ef3e2c03750588dab596247204e7f960b509af37f0001ac1e4ac23f2a/opentelemetry_instrumentation_asgi-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.42b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.42b0 from https://files.pythonhosted.org/packages/84/33/8e6b97dcb807c1ba5fd84910c091ae4b1b52d74ea24b0574e19f58cce99c/opentelemetry_instrumentation-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation-0.42b0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.42b0 from https://files.pythonhosted.org/packages/c3/0c/4c99cbe85b65fbba5a638cb7d913cb3acead3d83b4c47763be28d418bb95/opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.42b0 from https://files.pythonhosted.org/packages/3f/33/7528bd28710e3fd669ee7c5d98bc3392eb4588d451e28352696bb23c1520/opentelemetry_util_http-0.42b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_util_http-0.42b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for wrapt<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/49/83/b40bc1ad04a868b5b5bcec86349f06c1ee1ea7afe51dc3e46131e4f39308/wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for asgiref~=3.0 from https://files.pythonhosted.org/packages/9b/80/b9051a4a07ad231558fcd8ffc89232711b4e618c15cb7a392a17384bbeef/asgiref-3.7.2-py3-none-any.whl.metadata\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.17.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "INFO: pip is looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/95/b1/805141aa0c0024c633828375918838841481c8b977de8636ae2b80fdcad9/types_requests-2.31.0.9-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.9-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/1e/50/fb7eed30eace72d2eb6cf71059f896e7b4a0c031b654b99f37146a68d60b/types_requests-2.31.0.8-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.8-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/38/89/12bdcc3709cbc95120c1a4234becb8a94c7271806c36ee90bcf792df1f30/types_requests-2.31.0.7-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.7-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/5c/a1/6f8dc74d9069e790d604ddae70cb46dcbac668f1bb08136e7b0f2f5cd3bf/types_requests-2.31.0.6-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.6-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting types-urllib3 (from types-requests<3.0.0.0,>=2.31.0.2->langchainhub)\n",
      "  Obtaining dependency information for types-urllib3 from https://files.pythonhosted.org/packages/11/7b/3fc711b2efea5e85a7a0bbfe269ea944aa767bbba5ec52f9ee45d362ccf3/types_urllib3-1.26.25.14-py3-none-any.whl.metadata\n",
      "  Downloading types_urllib3-1.26.25.14-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: filelock in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/thyun/miniconda3/envs/langchain2/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for pyasn1<0.6.0,>=0.4.6 from https://files.pythonhosted.org/packages/d1/75/4686d2872bf2fc0b37917cbc8bbf0dd3a5cdb0990799be1b9cbf1e1eb733/pyasn1-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading langchain-0.0.345-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.18-py3-none-any.whl (502 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.4/502.4 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
      "Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.0.9-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.21.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.21.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.42b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.42b0-py3-none-any.whl (25 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.42b0-py3-none-any.whl (13 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.42b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.21.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.31.0.6-py3-none-any.whl (14 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.24.0-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.8/183.8 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
      "Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: types-urllib3, mmh3, wrapt, urllib3, types-requests, pyasn1, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, oauthlib, httpcore, googleapis-common-protos, distro, cachetools, asgiref, rsa, pyasn1-modules, opentelemetry-exporter-otlp-proto-common, httpx, deprecated, requests-oauthlib, opentelemetry-api, openai, langsmith, langchainhub, google-auth, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.6\n",
      "    Uninstalling urllib3-2.0.6:\n",
      "      Successfully uninstalled urllib3-2.0.6\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.43\n",
      "    Uninstalling langsmith-0.0.43:\n",
      "      Successfully uninstalled langsmith-0.0.43\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.311\n",
      "    Uninstalling langchain-0.0.311:\n",
      "      Successfully uninstalled langchain-0.0.311\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 0.4.14\n",
      "    Uninstalling chromadb-0.4.14:\n",
      "      Successfully uninstalled chromadb-0.4.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "poetry 1.6.1 requires jsonschema<4.18.0,>=4.10.0, but you have jsonschema 4.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.7.2 cachetools-5.3.2 chromadb-0.4.18 deprecated-1.2.14 distro-1.8.0 google-auth-2.24.0 googleapis-common-protos-1.61.0 httpcore-1.0.2 httpx-0.25.2 kubernetes-28.1.0 langchain-0.0.345 langchain-core-0.0.9 langchainhub-0.1.14 langsmith-0.0.69 mmh3-4.0.1 oauthlib-3.2.2 openai-1.3.7 opentelemetry-api-1.21.0 opentelemetry-exporter-otlp-proto-common-1.21.0 opentelemetry-exporter-otlp-proto-grpc-1.21.0 opentelemetry-instrumentation-0.42b0 opentelemetry-instrumentation-asgi-0.42b0 opentelemetry-instrumentation-fastapi-0.42b0 opentelemetry-proto-1.21.0 opentelemetry-sdk-1.21.0 opentelemetry-semantic-conventions-0.42b0 opentelemetry-util-http-0.42b0 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 types-requests-2.31.0.6 types-urllib3-1.26.25.14 urllib3-1.26.18 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain openai chromadb langchainhub bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a76ef4d-dbb7-42eb-992f-0be60147ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1ce327-6fdb-4bd0-8de4-e96817240a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b7f68b-b4e3-4cb6-8337-8040c8adef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90d92bc-7db7-4220-ac1c-36495be33db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa98a1bd-7e0d-4187-98c3-c309116789d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done through prompting techniques like Chain of Thought or Tree of Thoughts, or by using task-specific instructions or human inputs. Task decomposition helps agents plan ahead and tackle complicated tasks more effectively.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec0b85-c66a-4ee0-86a8-50a4230395de",
   "metadata": {},
   "source": [
    "## Step 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800957e4-9b1d-4186-b109-4b03e522536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833dafd8-ce72-4ab1-a9db-01abb35c58de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a20e27-200d-4c32-b4a2-1586ab2981db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc909554-b6dd-4034-aeb4-abc32529fb5f",
   "metadata": {},
   "source": [
    "## Step 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a35892-68e9-4fb2-b6ce-8dc1f6ef04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90607f7d-e2a0-4928-8c1b-614b592b08bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9362cf3-93fb-485e-8583-717cb7179c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'title': \"LLM Powered Autonomous Agents | Lil'Log\",\n",
       " 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbfd056-5581-46f5-8037-aee7e176f3ba",
   "metadata": {},
   "source": [
    "## Step 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04642e1e-ca23-4ef7-afc2-a1cc4373ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27998245-4a8e-418f-adf2-a203e3f64ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"What are the approaches to Task Decomposition?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f8ab4d-fea2-4221-86da-f2c0235963aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "562162de-3d07-4383-9617-7d11b651aa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e7f599a-0c34-41f2-afb9-3415ddb9a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb941333-c190-4137-992b-15d2556c2110",
   "metadata": {},
   "source": [
    "## Step 5. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cc857-953b-4039-8300-2c050e58f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://smith.langchain.com/hub/rlm/rag-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457afed2-9a25-4f82-af9e-2dc2e939e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    prompt.invoke(\n",
    "        {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    "    ).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b8a8ec8-c5ac-4096-8240-2e0f4298fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done through prompting techniques like Chain of Thought (CoT) or Tree of Thoughts, as well as task-specific instructions or human inputs. Task decomposition helps agents plan and execute complicated tasks more effectively."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is Task Decomposition?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee4a14-92b1-4be3-99ac-8073f28813a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b755efcd-a330-442b-bbe6-226de18d5df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done through prompting the model to think step by step or by providing task-specific instructions. Task decomposition helps in enhancing model performance and understanding the model's thinking process. Thanks for asking!\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt_custom = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9b681-32f5-415f-9385-7020c0606452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e30fad6a-7d7f-40a1-aa74-28ab08a94dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:',\n",
       "   'language': 'en',\n",
       "   'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       "   'title': \"LLM Powered Autonomous Agents | Lil'Log\"},\n",
       "  {'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:',\n",
       "   'language': 'en',\n",
       "   'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       "   'title': \"LLM Powered Autonomous Agents | Lil'Log\"},\n",
       "  {'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:',\n",
       "   'language': 'en',\n",
       "   'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       "   'title': \"LLM Powered Autonomous Agents | Lil'Log\"},\n",
       "  {'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:',\n",
       "   'language': 'en',\n",
       "   'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       "   'title': \"LLM Powered Autonomous Agents | Lil'Log\"}],\n",
       " 'answer': 'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It allows agents or models to better understand and plan for the individual components of a task. Thanks for asking!'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    {\n",
    "        \"context\": lambda input: format_docs(input[\"documents\"]),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | rag_prompt_custom\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"documents\": retriever, \"question\": RunnablePassthrough()}\n",
    ") | {\n",
    "    \"documents\": lambda input: [doc.metadata for doc in input[\"documents\"]],\n",
    "    \"answer\": rag_chain_from_docs,\n",
    "}\n",
    "\n",
    "rag_chain_with_source.invoke(\"What is Task Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2061ef-a77c-4b10-9bee-9334c4116a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522ed30a-ba92-4acc-9dc7-288eae56c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "condense_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "condense_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", condense_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "condense_q_chain = condense_q_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "971a0b99-564e-4555-8b0c-128900bfb50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the definition of \"large\" in the context of a language model?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "\n",
    "condense_q_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does LLM stand for?\"),\n",
    "            AIMessage(content=\"Large language model\"),\n",
    "        ],\n",
    "        \"question\": \"What is meant by large\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ce4a8d-4a4a-453e-94a3-665669e491e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do transformer models function?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condense_q_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does LLM stand for?\"),\n",
    "            AIMessage(content=\"Large language model\"),\n",
    "        ],\n",
    "        \"question\": \"How do transformers work\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4e8b94-b9b4-4ef7-9f4f-7e17d7fd70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def condense_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return condense_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(context=condense_question | retriever | format_docs)\n",
    "    | qa_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5fa6b50-4094-4cb9-b55b-2abad821ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Common ways of task decomposition include:\\n\\n1. Using Chain of Thought (CoT): CoT is a prompting technique where the model is instructed to \"think step by step\" and decompose complex tasks into smaller and simpler steps. This technique utilizes more test-time computation and helps the model understand and interpret its thinking process.\\n\\n2. Task-specific instructions: For certain tasks, specific instructions can be provided to guide the task decomposition process. For example, in the context of writing a novel, the instruction \"Write a story outline\" can help break down the task into subgoals and steps.\\n\\n3. Human inputs: Task decomposition can also be done with the help of human inputs. Humans can provide guidance, expertise, or domain-specific knowledge to assist in breaking down the task into manageable subtasks or steps.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg])\n",
    "\n",
    "second_question = \"What are common ways of doing it?\"\n",
    "rag_chain.invoke({\"question\": second_question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831534fe-1a68-40ca-931b-414f5f09b4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0eac90-9b9a-487c-8c72-badd5f1fbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea595c-fbbf-4073-85b8-df2585407498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38610d65-ed46-439a-8892-197e74bc6082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1663061-2e02-405f-830e-94cce3fde8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af12b0-6e85-4eca-bcec-1c5bd8589acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80556c13-7d44-4840-ba0a-a48fec5590cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
